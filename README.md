# Dog-Breed-Identification-Using-Keras-Xception
# Introduction
Our Project focuses on the use of neural networks for analyzing the dog data set composed of records with dog image files which are classified into different breeds. Dogs are one of the diverse species on earth both morphologically and genetically. The interbreed variations are relatively low when compared to intra-breed variations. So, this is a fine-grained classification problem. These difficulties in diversity are compounded by the stylistic differences of images used in the dataset, which features of dogs of identical breed in a variety of lightings and positions. These studies are useful for assessing the status of the ecosystems and also help veterinarians to treat breed specific ailments stray, unidentified dogs that need medical care. 
# Dataset Description 
The dataset is taken from the Dog Breed Identification challenge hosted by Kaggle (a platform for Data-Science Competitions). Data is provided as training and test set of images of dogs. The training data set consists of 10357 dog images with 120 different classes. Each data image has a filename which is its unique id. The training set also consists of 10357 test images. These total images are needs to be classified into 120 classes and the result should be CSV file for submission.  
We grouped all the breeds into a list ‘selected_breed_list’. This list contains all the 120 classes(breeds) which we are going to classify our images into these classes. 
# preprocessing 
We performed data augmentation on our data which improved performance in extracting features and fit to our model. For preprocessing our data, we basically used Xception preprocessing, horizontal flipping, shifting and standard normalization. 
We used Keras Deep Learning Python Library in our project for training, testing and Preprocessing of data. Keras can run on Tensor Flow. Deep Learning Models are available in Python which is compact, easier to debug, and allows for ease of extensibility. It supports both CNN & RNN and combination of both as well. It is easy and allows fast prototyping for the user where we can directly call all the required models with keras suffix easily. 
# Base Line Model 
We started implementing with Four layer CNN with input image scaled to 220 *220. Convolution layers are implemented with stride 5 and stride 2. But this model didn’t perform well on our data set. We tried Alexnet which we were replicating the paper of image classification. Even this doesn’t perform well. Google Net was also implemented which resulted the similar accuracy of the above two. The above models performed not as expected resulting accuracy not more than 15- 20 percent.
# Improvements 
As we were using Keras for preprocessing, we tried keras models for our project. Starting with VGG19 which is 19 layer network. Inception Resnet and Xception are also tried. These two models are performing better than other models in Keras with 94 and 95 accuracy rate respectively.  
These models are based on a pattern recognition network. After presenting several examples of images, the network gets used to small details, middle sized features or almost whole images if they come up very often.  
Each layer of the network reinforces some features it thinks is there and passes on to the next. With respect our project we trained a convolutional neural network on images of dogs and their annotated facial key points (right eye, left eye, right ear tip, right ear base, head top, left ear tip and left ear base). We used this network on the test set of dog images. These predicted key points were then fed into a feature extraction system that used these key points to create more meaningful features from the original image which could be used to classify the image. 
 After fitting our models to the data set, we tried concatenating both Xception and Inception Resnet model which improved performance when compared to individual implementation. To avoid overfitting, we used drop out point with value ‘0.95’. 
Softmax Activation function is used and Adam Optimizer is used initially. But later SGD is used which  performed better than Adam.
 
